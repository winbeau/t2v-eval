[project]
name = "t2v-eval"
version = "0.1.0"
description = "Unified evaluation pipeline for text-to-video generation with official metric implementations"
readme = "README.md"
license = { text = "MIT" }
requires-python = ">=3.10,<3.11"
authors = [
    { name = "Your Name", email = "your.email@example.com" }
]
keywords = ["text-to-video", "evaluation", "vbench", "clip", "video-generation"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]

dependencies = [
    # Core
    "numpy>=1.21.0",
    "pandas>=1.3.0",
    "pyyaml>=6.0",
    "tqdm>=4.62.0",
    "pillow>=8.0.0",
    # HuggingFace
    "datasets>=2.14.0",
    "huggingface-hub>=0.16.0",
    # Video processing
    "decord>=0.6.0",
    "opencv-python>=4.5.0",
    # PyTorch (user should install separately for CUDA support)
    "torch>=2.0.0",
    "torchvision>=0.15.0",
    # CLIP/VQA
    "open-clip-torch>=2.20.0",
    "transformers>=4.30.0",
    # Image quality
    "pyiqa>=0.1.7",
    "t2v-metrics",
    "gdown>=5.2.1",
]

[project.optional-dependencies]
dev = [
    "black>=22.0.0",
    "ruff>=0.1.0",
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
]

vbench = [
    # From third_party/VBench/requirements.txt
    "Pillow",
    "numpy<2.0.0",
    "matplotlib",
    "timm>=0.9,<=1.0.12",
    "wheel",
    "cython",
    "tensorboard",
    "scipy",
    "opencv-python",
    "scikit-learn",
    "scikit-image",
    "openai-clip",
    "decord",
    "requests",
    "pyyaml",
    "easydict",
    "pyiqa",
    "lvis",
    "fairscale>=0.4.4",
    "fvcore",
    "urllib3",
    "boto3",
    "omegaconf",
    "transformers==4.33.2",
    "pycocoevalcap",
]

vbench-competition = [
    # From third_party/VBench/competitions/requirements.txt (legacy, pinned)
    "Pillow==9.5.0",
    "numpy",
    "matplotlib",
    "timm==0.9.12",
    "torch==1.13.1",
    "torchvision>=0.13",
    "tensorboard",
    "scipy==1.10.1",
    "opencv-python",
    "scikit-learn",
    "requests",
    "scikit-image",
    "pyyaml",
    "easydict",
    "lvis",
    "fairscale==0.4.4",
    "openai-clip",
    "fvcore",
    "decord==0.6.0",
    "pyiqa==0.1.8",
    "transformers==4.33.2",
    "pycocoevalcap",
    "wheel",
    "cython",
    "urllib3",
    "boto3",
    "omegaconf",
    "pyav",
    "av",
    "moviepy",
]

t2v-metrics = [
    # From third_party/t2v_metrics/pyproject.toml (deduped)
    "torch==2.5.1",
    "torchvision==0.20.1",
    "torchaudio==2.5.1",
    "xformers",
    "ftfy>=6.1.1",
    "tqdm>=4.64.1",
    "gdown>=4.7.1",
    "huggingface-hub>=0.19.4",
    "matplotlib>=3.6.2",
    "numpy==1.26.4",
    "open-clip-torch>=2.23.0",
    "openai",
    "opencv-python>=4.11.0.86",
    "opencv-python-headless",
    "pandas>=2.1.4",
    "scipy>=1.11.4",
    "sentencepiece>=0.1.99",
    "transformers==4.49.0",
    "datasets>=2.15.0",
    "tokenizers",
    "omegaconf",
    "iopath",
    "fairscale",
    "scikit-learn",
    "pycocoevalcap",
    "hpsv2",
    "clip @ git+https://github.com/openai/CLIP.git",
    "llava @ git+https://github.com/LLaVA-VL/LLaVA-NeXT.git",
    "fire==0.4.0",
    "tiktoken>=0.7.0",
    "peft==0.5.0",
    "matplotlib-inline",
    "decord",
    "easydict",
    "protobuf",
    "pytz",
    "av",
    "icecream",
    "markdown2",
    "pydantic",
    "accelerate",
    "shortuuid",
    "bitsandbytes",
    "requests",
    "httpx==0.24.0",
    "uvicorn",
    "einops-exts",
    "einops",
    "PyYAML",
    "wandb",
    "torchcodec==0.1",
    "moviepy",
    "apex==0.9.10dev",
    "deepspeed",
    "fvcore==0.1.5.post20221221",
    "imageio==2.31.1",
    "librosa==0.10.1",
    "Pillow==10.0.0",
    "psutil==5.9.5",
    "soundfile==0.12.1",
    "termcolor==2.4.0",
    "qwen-vl-utils",
    "flash-attn @ https://github.com/Dao-AILab/flash-attention/releases/download/v2.5.8/flash_attn-2.5.8+cu122torch2.3cxx11abiFALSE-cp310-cp310-linux_x86_64.whl",
    "func_timeout",
    "timm>=1.0.15",
    "gitpython",
    "google-genai",
    "blobfile",
    "pytorchvideo @ git+https://github.com/linzhiqiu/pytorchvideo.git",
    "diffusers",
    "nltk",
    "rouge-score",
]

all = [
    "t2v-eval[dev,vbench,t2v-metrics]",
]

[project.urls]
Homepage = "https://github.com/YOUR_USERNAME/t2v-eval"
Repository = "https://github.com/YOUR_USERNAME/t2v-eval"
Documentation = "https://github.com/YOUR_USERNAME/t2v-eval#readme"

[project.scripts]
t2v-eval = "scripts.run_all:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["scripts"]

[tool.uv]
[tool.uv.workspace]
members = [
    "third_party/t2v_metrics",
]

[tool.uv.sources]
t2v-metrics = { workspace = true, editable = true }

[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = ["E", "F", "W", "I", "N", "UP", "B", "C4"]
ignore = ["E501"]

[tool.black]
line-length = 100
target-version = ["py310", "py311", "py312"]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
addopts = "-v --tb=short"

[dependency-groups]
dev = [
    "black>=22.0.0",
    "ruff>=0.1.0",
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
]
