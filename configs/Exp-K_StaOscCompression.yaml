# =============================================================================
# T2V-Eval Configuration - Exp-K_StaOscCompression
# 7 groups (local videos)
# =============================================================================

dataset:
  repo_id: "kv-compression/AdaHead"
  split: "train"
  use_local_videos: true
  local_video_dir: "hf/AdaHead/Exp-K_StaOscCompression"
  # This pipeline currently accepts a single prompt_file.
  # Assume all groups share the same prompt set keyed by video_id.
  # If prompts differ by group, merge prompts first and then update prompt_file.
  prompt_file: "hf/AdaHead/Exp-K_StaOscCompression/k1_selfforcing_absolute21_baseline/prompts.csv"
  video_dir: "videos/Exp-K_StaOscCompression"

groups:
  - name: "k1_selfforcing_absolute21_baseline"
    description: "Self-forcing absolute-21 baseline"
    latent_frames: 120
    actual_frames: 480
  - name: "k2_selfforcing_dynamic21_baseline"
    description: "Self-forcing dynamic-21 baseline"
    latent_frames: 120
    actual_frames: 480
  - name: "k3_sta_posneg_osc_phase6_tail4"
    description: "Static pos/neg oscillation, phase6 tail4"
    latent_frames: 120
    actual_frames: 480
  - name: "k4_dynamic_sink1_af_quality"
    description: "Dynamic sink1 AF quality variant"
    latent_frames: 120
    actual_frames: 480
  - name: "k5_sta_posneg_osc_phase6_tail4_nodynrope"
    description: "Static pos/neg oscillation phase6 tail4 (no dynrope)"
    latent_frames: 120
    actual_frames: 480
  - name: "k6_deep_forcing"
    description: "Deep forcing variant"
    latent_frames: 120
    actual_frames: 480
  - name: "k7_native_self_forcing_static21_sink1"
    description: "Native self-forcing static21 sink1"
    latent_frames: 120
    actual_frames: 480

protocol:
  fps_eval: 8
  num_frames: 288
  resize: 256
  frame_sampling: "uniform"
  frame_padding: "loop"

metrics:
  enabled:
    - "clip_or_vqa"
    - "vbench_temporal"
    - "flicker"
    - "niqe"

  clip_or_vqa:
    mode: "clip"
    model_name: "ViT-B-32"
    pretrained: "openai"
    num_frames_for_score: 288
    aggregation: "mean"

  vbench:
    enabled: true
    backend: "vbench_long"
    use_long: true
    dimension_profile: "long_16"
    mode: "long_custom_input"
    use_semantic_splitting: false
    clip_length_config: "clip_length_mix.yaml"
    static_filter_flag: false
    scene_threshold: 35.0
    sb_clip2clip_feat_extractor: "dino"
    bg_clip2clip_feat_extractor: "clip"
    subtasks:
      - "subject_consistency"
      - "background_consistency"
      - "temporal_flickering"
      - "motion_smoothness"
      - "temporal_style"
      - "appearance_style"
      - "scene"
      - "object_class"
      - "multiple_objects"
      - "spatial_relationship"
      - "human_action"
      - "color"
      - "overall_consistency"
      - "dynamic_degree"
      - "imaging_quality"
      - "aesthetic_quality"

  flicker:
    method: "l1"
    normalize: true
    compute_std: true
    grayscale: false

  niqe:
    enabled: true
    num_frames_for_niqe: 288
    block_size: 96
    alternative: "niqe"

runtime:
  device: "cuda"
  batch_size: 1
  num_workers: 4
  seed: 42

paths:
  cache_dir: "./eval_cache"
  output_dir: "./outputs/Exp-K_StaOscCompression"
  metadata_file: "metadata.csv"
  processed_metadata: "processed_metadata.csv"
  per_video_metrics: "per_video_metrics.csv"
  group_summary: "group_summary.csv"
  runtime_csv: "runtime.csv"
  figures_dir: "./outputs/Exp-K_StaOscCompression/figs"
  experiment_output: "Exp-K_StaOscCompression.csv"

logging:
  level: "INFO"
  log_file: "./outputs/Exp-K_StaOscCompression/eval.log"
  console: true
